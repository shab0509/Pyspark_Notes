Pyspark and pandas:

import findspark
findspark.init()
findspark.find()

import pyspark
from pyspark.sql import SparkSession
spark=SparkSession.builder.getOrCreate()
df=spark.sql("select 'spark' as BigData")
df.show()
+-------+
|BigData|
+-------+
|  spark|
+-------+

!pip install pandas
!pip install pyarrow

import pyspark.pandas as ps

WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to 
set this environment variable to '1' in both driver and executor sides if you use 
pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark 
context already launched.

df1=ps.read_csv("C:\data1\emp1.csv")
print(df1)

  Eid   Ename  Salary sex  dno  city
0  101  Miller   10000   m   11   hyd
1  102   Blake   20000   m   12  pune
2  103    Sony   30000   f   11   hyd
3  104    Sita   40000   f   12  pune
4  105    John   50000   m   13   hyd


type(df1)

o/p: pyspark.pandas.frame.DataFrame

pyspark pandas dataframe is present in multiple machines(distributed)

df1.dno.value_counts()

o/p:
11    2
12    2
13    1

df1.Salary.max()
o/p:50000

#Converting pyspark pandas datadrame to pandas dataframe
pandas_df=df1.to_pandas()
print(pandas_df)

o/p: 
  Eid   Ename  Salary sex  dno  city
0  101  Miller   10000   m   11   hyd
1  102   Blake   20000   m   12  pune
2  103    Sony   30000   f   11   hyd
3  104    Sita   40000   f   12  pune
4  105    John   50000   m   13   hyd

type(pandas_df)
pandas.core.frame.DataFrame

pandas_df.dno.value_counts()

o/p:
11    2
12    2
13    1

pandas_df.Salary.max()
o/p: 50000

#converting to spark dataframe
spark_df=df1.to_spark()
spark_df.show()

o/p:
+---+------+------+---+---+----+
|Eid| Ename|Salary|sex|dno|city|
+---+------+------+---+---+----+
|101|Miller| 10000|  m| 11| hyd|
|102| Blake| 20000|  m| 12|pune|
|103|  Sony| 30000|  f| 11| hyd|
|104|  Sita| 40000|  f| 12|pune|
|105|  John| 50000|  m| 13| hyd|
+---+------+------+---+---+----+

spark_df.filter('dno=12').show()

o/p:
+---+-----+------+---+---+----+
|Eid|Ename|Salary|sex|dno|city|
+---+-----+------+---+---+----+
|102|Blake| 20000|  m| 12|pune|
|104| Sita| 40000|  f| 12|pune|
+---+-----+------+---+---+----+

type(spark_df)
pyspark.sql.dataframe.DataFrame


#converting spark_df to pyspark.pandas.dataframe
psdf=spark_df.pandas_api()
psdf.sort_index(ascending=False)

	Eid	Ename	Salary	sex	dno	city
4	105	John	50000	m	13	hyd
3	104	Sita	40000	f	12	pune
2	103	Sony	30000	f	11	hyd
1	102	Blake	20000	m	12	pune
0	101	Miller	10000	m	11	hyd

type(psdf)

o/p:
pyspark.pandas.frame.DataFrame





