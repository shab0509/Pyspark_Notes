Stages and Tasks:
-----------------------------------------------------------------------------------------------

Spark Features:

1.In-memory Computing---->Data loads in memory
                          Data processed in memory
2.Lazy Evolution------>Transformations are executed only when actions are performed
3.Distributed Execution
4.Parallel Processing
5.Resilience--->During Fault-Tolerance ,Spark has a feature of regenerating the lost partitions
                of a RDD
6.Persistence-->Making the RDD available in RAM
7.Stages and Tasks
-----------------------------------------------------------------------------------------------

2 Types of Transformations:

1.Narrow Transformation-------->No Shuffling of data involved
2.Wide Transformation --------->Shuffling of data involved

---------------------------------------------------------------------------------------------

When we launch a Spark Application , what happens internally??

when we submit or launch spark application to any cluster then 2 kinds of programs 
will be created

1)Driver -------->acts as master process
2)Executor-------->acts as a slave process

These are master and slave w.r.to Spark Application but not w.r.to spark cluster

w.r.to Spark cluster

 cluster     MAster          slave         Master portno
1.YARN       Resource        Node          RM ---->8088
             MAnager(RM)     MAnager(NM)

2.Standalone  Sparkmaster    sparkworker    sparkmaster-->7077


stages and Tasks belongs to Driver and Executor

when a Spark Application is submitted to a YARN Cluster then we require some resources

for running the Application in slave nodes such as
1)Memory
2)Processor(cores)

These resources are allocated by NodeMAnager of each node

RM---->Maintains the entire cluster
NM --->Maintains the entire Node

SparkApplication----submitted to RM


                                     DN1        DN2        DN3
                                     NM1        NM2        NM3
                                     Block1     Block2     Block3
                                     partition1 partition2 PArtition3


All the NodeManagers will be under the RM
Blocks are stored in Datanodes
from Blocks partitions are created by allocating the resources by NM
Generally Partitions need to be processed with a B.L

we perform opertions over the partitions or data

who supplies the logic(or) operations to be performed on the data------>Driver

o
                              supplies logic
SparkApp----creates---->Driver------------>p1   -----------> p2   ---------->p3
                        program            NM1              NM2              NM3
                                           DN1              DN2              DN3
                                         Executor        Executor          Executor    
 
Spark Application creates a Driver program
Driver profram supplies logic (or) operations to Each partition of slave node

The Execution of the partition with the provided logic is carried out by a program
calles as Executor
          --------

Executor program will process the partition data based on the logic provided

if 3 partitions----->then 3 Executor programs will run

No of Executors=No of Partitions

All these Executors runs under the control of Driver

Thats why Driver is the master of Spark Application
      Executor is the slave of Spark Application

----------------------------------------------------------------------------------------------

Task: A Task is nothing but a partition under execution---->It is a state

       IT is a state of execution of a partition(but it is not a process)

 No of Tasks= No of Partitions =No of Executors


---------------------------------------------------------------------------------------------
Stages:

 r1= sc.textFile("........")-->3 partitions----> p1    p2    p3 *t1---------->
                                                     |      |     | 
 r2= r1.t1() ----->Narrow Transformation  r2---> p1    p2    p3 *t2
                       (No Shuffling)                 |     |     |
 r3= r2.t2() ----->Narrow Transformation  r3---> p1    p2    p3 *t3
                       (No Shuffling)               \/     \/--------->Here data gets shuffled
                                                    /\     /\      ------->upto here stage1
 r4= r3.t3() ----->Wide   Transformation  r4---> p1    p2    p3 *t4
                       (Shuffling happens)           |     |      |
 r5= r4.t4() ----->Narrow Transformation  r5---> p1    p2    p3 *t5------>upto here stage2
                        (No Shuffling)
                                                     \/     \/--------->Here data gets shuffled
                                                     /\     /\
 r6= r5.t5() ----->Wide   Transformation  r6---> p1    p2    p3    ----------->stage3


when a wide Transformation is applied  on a RDD, then a new stage will be created.

No.of Stages=No of wide Transformations+1
-----------------------------------------

in the above example--->No of wide Transformations=2
                     so No of Stages =wide T/R +1
                                     =2 +1
                                     =3stages(stage1,stage2,stage3)

Here data is shuffled for 2 times--->so no of stages =3

if data is shuffled for 4 times---->No of stages=5

if 5 stages are created---->No.of wide Transformations===>4
-----------------------------------------------------------------------------------------------
what is a stage--->
Stage: A Stage is a collection of all RDDS or Transformations which doent involve shuffling
        once shuffling involved means new stage will be created

From a RDD to RDD ,if data is flowing without shuffling then it is a stage.

-If shuffling is involved then a new stage is created.

--------------------------------------------------------------------------------------
Relation b/w Stage and Task

RDD---->3 partitions---(p1,p2,p3)x T/R1 applied on each parition
          executor=(partition+T/R)
          3 partitions --->3 Executors ------>3 Tasks


       B1      B2      B3
        |       |       |
rdd1--->P1      P2      P3 (p1,p2,p3)*t1 ===>3 Executors, 3 Tasks----------------------->
 N.T    |t1     |t1     |t1
 
rdd2--->P1      P2      P3 (p1,P2,P3)*t2 ===>3 Executors ,3 Tasks          ------->Stage 1
N.T     |t2     |t2     |t2

rdd3--->P1      P2      P3 (p1,P2,P3)*t3===>3 Executors ,3 Tasks----------------------->
W.T         \       \ (here shuffling happens within the partitions)
rdd4--->P1      P2      P3 (p1,P2,P3)*t4===>3 Executors ,3 Tasks------->--------stage2 starts
N.T     |t4     |t4     |t4                                     untill when stage2 continues??
                                                        untill another wide T/R is encountered
rdd5--->P1      P2      P3 (p1,P2,P3)*t5===>3 Executors ,3 Tasks------->
N.T     |t5     |t5     |t5
rdd6--->P1      P2      P3 (p1,P2,P3)*t6===>3 Executors ,3 Tasks------->--------Stage 2 ends
W.T     |t6     |t6     |t6(here shuffling happens)

rdd7--->P1      P2      P3 (p1,P2,P3)*t7===>3 Executors ,3 Tasks-------> stage3 starts
N.T     |t7     |t7     |t7



As long as the T/Rs are Narrow ,they fall in the same Stage

whenever shuffling happens----->a new stage is created


Stage: Execution of sequence of Narrow Transformations

New Stage -->gets created for a wide T/R.

Executor: Program which process a partition

Task : A partition under Execution


Driver :which monitors the Executors
        i.e whether are killed /running

Driver wont process the partitions

only Executors process the partitions

----------------------------------------------------------------------------------------------

1Q)If no of wide transformations=4--->then no of stages=5
2Q)If no of stages=4 ----->then no of wide Transformations=3
3)If no of partitions=4--->Then no of executors=4
4)If no of partitions=4--->then no of tasks=4
5)If no of executors=4---->then no of tasks=4
6)If no of tasks=3 ------>then no of executors=3
7)If no of executors=3--->then no of drivers=1
-----------------------------------------------------------------------------------------------









 




















































