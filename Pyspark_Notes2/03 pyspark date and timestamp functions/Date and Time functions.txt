PySpark SQL Functions
----------------------
Pyspark Date and Timestamp Functions

DateType-------> default format is------> yyyy-MM-dd 
TimestampType---> default format is-----> yyyy-MM-dd HH:mm:ss.SSSS

Date and Time are very important if you are using PySpark for ETL

PySpark SQL provides several Date & Timestamp functions

Pyspark Date Functions

1.current_date() :	Returns the current system date 

from pyspark.sql import SparkSession
from pyspark.sql.functions import *

# Create SparkSession
spark = SparkSession.builder \
            .appName('DemoApp') \
            .getOrCreate()
data=[["1","2022-02-01"],["2","2021-03-01"],["3","2023-03-01"]]
df=spark.createDataFrame(data,["id","date"])
df.show()

+---+----------+
| id|      date|
+---+----------+
|  1|2022-02-01|
|  2|2021-03-01|
|  3|2023-03-01|
+---+----------+

------------------------------------------------------------------------------------------
1.current_date() :	Returns the current system date 

df.select(current_date().alias("current_date")).show(1)
+------------+
|current_date|
+------------+
|  2023-07-15|
+------------+
only showing top 1 row
----------------------------------------------------------------------------------------
2.date_format() :converts date from yyyy-dd-mm to MM-dd-yyyy format.

df.select(col("date"), 
    date_format(col("date"), "MM-dd-yyyy").alias("date_format") 
  ).show()

+----------+-----------+
|      date|date_format|
+----------+-----------+
|2022-02-01| 02-01-2022|
|2021-03-01| 03-01-2021|
|2023-03-01| 03-01-2023|
+----------+-----------+

------------------------------------------------------------------------------------------
3.to_date():converts string in date format yyyy-MM-dd to a DateType yyyy-MM-dd

df.select(col("date"), 
    to_date(col("date"), "yyy-MM-dd").alias("to_date") 
  ).show()

+----------+----------+
|      date|   to_date|
+----------+----------+
|2022-02-01|2022-02-01|
|2021-03-01|2021-03-01|
|2023-03-01|2023-03-01|
+----------+----------+

------------------------------------------------------------------------------------------
4.datediff():returns the difference between two dates 

#datediff()
df.select(col("date"), 
    datediff(current_date(),col("date")).alias("datediff")  
  ).show()

+----------+--------+
|      date|datediff|
+----------+--------+
|2022-02-01|     529|
|2021-03-01|     866|
|2023-03-01|     136|
+----------+--------+
------------------------------------------------------------------------------------------
5.months_between(): returns the months between two dates

df.select(col("date"), 
    months_between(current_date(),col("date")).alias("months_between")  
  ).show()

+----------+--------------+
|      date|months_between|
+----------+--------------+
|2022-02-01|    17.4516129|
|2021-03-01|    28.4516129|
|2023-03-01|     4.4516129|
+----------+--------------+

-------------------------------------------------------------------------------------------
6.add_months() , date_add(), date_sub():
adding and subtracting date and month from a given input.

#add_months() , date_add(), date_sub()
df.select(col("date"), 
    add_months(col("date"),3).alias("add_months"), 
    add_months(col("date"),-3).alias("sub_months"), 
    date_add(col("date"),4).alias("date_add"), 
    date_sub(col("date"),4).alias("date_sub") 
  ).show()

+----------+----------+----------+----------+----------+
|      date|add_months|sub_months|  date_add|  date_sub|
+----------+----------+----------+----------+----------+
|2022-02-01|2022-05-01|2021-11-01|2022-02-05|2022-01-28|
|2021-03-01|2021-06-01|2020-12-01|2021-03-05|2021-02-25|
|2023-03-01|2023-06-01|2022-12-01|2023-03-05|2023-02-25|
+----------+----------+----------+----------+----------+

-------------------------------------------------------------------------------------------
7.year(), month(), month(),next_day(), weekofyear()

df.select(col("date"), 
     year(col("date")).alias("year"), 
     month(col("date")).alias("month"), 
     next_day(col("date"),"Sunday").alias("next_day"), 
     weekofyear(col("date")).alias("weekofyear") 
  ).show()

+----------+----+-----+----------+----------+
|      date|year|month|  next_day|weekofyear|
+----------+----+-----+----------+----------+
|2022-02-01|2022|    2|2022-02-06|         5|
|2021-03-01|2021|    3|2021-03-07|         9|
|2023-03-01|2023|    3|2023-03-05|         9|
+----------+----+-----+----------+----------+

-------------------------------------------------------------------------------------------
8.dayofweek(), dayofmonth(), dayofyear()

df.select(col("date"),  
     dayofweek(col("date")).alias("dayofweek"), 
     dayofmonth(col("date")).alias("dayofmonth"), 
     dayofyear(col("date")).alias("dayofyear"), 
  ).show()

+----------+---------+----------+---------+
|      date|dayofweek|dayofmonth|dayofyear|
+----------+---------+----------+---------+
|2022-02-01|        3|         1|       32|
|2021-03-01|        2|         1|       60|
|2023-03-01|        4|         1|       60|
+----------+---------+----------+---------+

------------------------------------------------------------------------------------------
9.hour(), Minute() and second()

#hour, minute,second
data=[["1","2020-02-01 11:01:19.06"],["2","2019-03-01 12:01:19.406"],["3","2021-03-01 12:01:19.406"]]
df3=spark.createDataFrame(data,["id","input"])

df3.select(col("input"), 
    hour(col("input")).alias("hour"), 
    minute(col("input")).alias("minute"),
    second(col("input")).alias("second") 
  ).show(truncate=False)

+-----------------------+----+------+------+
|input                  |hour|minute|second|
+-----------------------+----+------+------+
|2020-02-01 11:01:19.06 |11  |1     |19    |
|2019-03-01 12:01:19.406|12  |1     |19    |
|2021-03-01 12:01:19.406|12  |1     |19    |
+-----------------------+----+------+------+

------------------------------------------------------------------------------------------




